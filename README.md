Here is a **professional README.md** you can copy directly into your repository.
(Screenshot placeholders included â€” replace with your images later.)

---

### âœ… **README.md (Ready to copy)**

```markdown
# ğŸ¤– AI Assistant â€” OpenAI Responses API Examples  
_Automate. Stream. Execute real actions with AI._

---

## ğŸš€ Overview

This repository contains multiple **real-world examples** demonstrating how to build an AI assistant using the **OpenAI Responses API** with:

âœ… Function / Tool calling  
âœ… Streaming responses (real-time incremental text output)  
âœ… FastAPI backend + streaming to browser  
âœ… Streamlit chatbot application  
âœ… Persistent conversation history  
âœ… Modular architecture for adding new actions (send email, calendar event, etc.)

---

## ğŸ–¥ï¸ Demo Screenshots

| Streamlit Chatbot UI | FastAPI + Web Frontend |
|--------------------|----------------------|
| ![Streamlit Screenshot](./screenshots/streamlit_ui.png) | ![FastAPI Web UI](./screenshots/fastapi_ui.png) |

> *(Add screenshots into `/screenshots` folder â€” the file names will match.)*

---

## ğŸ“‚ Project Structure

```

ai-web-assistant/
â”‚
â”œâ”€â”€ main.py                 # FastAPI app (streaming + tool execution)
â”œâ”€â”€ config.py               # API key config (ignored via .gitignore)
â”œâ”€â”€ requirements.txt
â”‚
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html          # Browser chat frontend (FastAPI app)
â”‚
â”œâ”€â”€ static/
â”‚   â””â”€â”€ script.js           # Frontend JS for streaming messages
â”‚
â”œâ”€â”€ screenshots/
â”‚   â”œâ”€â”€ streamlit_ui.png
â”‚   â”œâ”€â”€ fastapi_ui.png

````

---

## âœ¨ Features

| Feature | Description |
|--------|-------------|
| ğŸ› ï¸ **Tool Calling** | AI calls real Python functions â€” calendar event, email, etc. |
| âš¡ **Streaming Responses** | Real-time word-by-word streaming from OpenAI |
| ğŸ”„ **Persistent Memory** | Saves conversation history into JSON |
| ğŸŒ **FastAPI SSE Endpoint** | Browser connects and streams messages |
| ğŸª„ **Streamlit UI** | Minimal chat app with real-time response streaming |

---

## ğŸ”§ Tool Calling Examples

### âœ”ï¸ Example: Calendar Event (AI triggers a Python function)

```python
def create_calendar_event(title, date, time, attendee):
    return f"[Action] Calendar event: {title} on {date} at {time} with {attendee}"
````

### âœ”ï¸ Example: Send an Email

```python
def send_email(to, subject, body):
    return f"[Action] Sending Email to {to} | Subject: {subject}"
```

---

## ğŸ§  OpenAI Responses API (streaming)

```python
stream = client.responses.create(
    model="gpt-4.1-mini",
    input=messages,
    tools=tools,
    stream=True
)
```

Events are streamed:

```python
for event in stream:
    if event.type == "response.output_text.delta":
        print(event.delta) # <-- streaming text
```

---

## â–¶ï¸ Run the Streamlit App

```bash
streamlit run app.py
```

---

## â–¶ï¸ Run the FastAPI Backend

```bash
uvicorn main:app --reload
```

Open browser:
ğŸ‘‰ [http://127.0.0.1:8000](http://127.0.0.1:8000)

---

## ğŸ” Configuration

Create `config.py` (not pushed to GitHub):

```python
OPENAI_API_KEY = "your_key_here"
```

---

## ğŸ“¦ Install Dependencies

```bash
pip install -r requirements.txt
```

`requirements.txt`

```
openai
fastapi
uvicorn
streamlit
jinja2
python-dotenv
python-multipart
```

---


And add to `tools[]`.

---

## ğŸ¤ Contributing

PRs are welcome!
Feel free to add new tools / examples.

---

## ğŸ“„ License

This project is released under the **MIT License**.

---

**â­ If this repository helped you, give it a star!**

```

